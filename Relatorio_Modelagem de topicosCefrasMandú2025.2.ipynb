{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b12089",
   "metadata": {},
   "source": [
    "# <center>__MÉTODOS NUMÉRICOS__</center>\n",
    "## <center>__MODELAGEM DE TÓPICOS COM NMF__</center>\n",
    "#### <center>__Aluno:__ Cefras Mandú</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59dea8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\cefra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\cefra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.16.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.8/8.9 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/8.9 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 19.1 MB/s  0:00:00\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   ---------------------------------------- 3/3 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e87e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0caa1f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "1. INTRODUÇÃO\n",
    "</div>\n",
    "\n",
    "Este trabalho aborda a técnica de Modelagem de Tópicos (*Topic Modeling*), uma área do Processamento de Linguagem Natural (NLP). Utilizamos métodos numéricos de fatoração para descobrir temas abstratos ocultos em uma coleção de documentos de texto não rotulados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882367c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "2. DESCRIÇÃO DO PROBLEMA\n",
    "</div>\n",
    "\n",
    "O problema consiste em organizar, entender e resumir grandes volumes de texto sem leitura humana direta. Dado um conjunto de documentos (corpus), o desafio é agrupar palavras que aparecem juntas frequentemente para formar \"tópicos\" e classificar cada documento com base nesses tópicos. É amplamente usado em análise de sentimentos, categorização de notícias e sistemas de busca jurídica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017e1d39",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "3. MÉTODOS APLICADOS À SOLUÇÃO\n",
    "</div>\n",
    "\n",
    "Aplicamos a **Fatoração de Matriz Não-Negativa (NMF)**. Diferente do SVD, o NMF decompõe a matriz de entrada $V$ (Documentos $\\times$ Palavras) em duas matrizes $W$ e $H$ com a restrição de que nenhum elemento seja negativo.\n",
    "$$V \\approx WH$$\n",
    "* **Por que é útil?** A restrição de não-negatividade torna o resultado interpretável. Como textos são compostos pela *soma* de significados (e não subtração), o NMF nos dá uma representação baseada em partes: $H$ mostra quais palavras compõem um tópico e $W$ mostra o peso desse tópico em cada documento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d0834",
   "metadata": {},
   "source": [
    "Explicação do código:\n",
    "\n",
    "1. Corpus de Texto\n",
    "    \n",
    "        documents = [\n",
    "    \n",
    "Esporte\n",
    "\n",
    "        \"O atacante chutou a bola no gol\",              \n",
    "    \n",
    "Tech    \n",
    "\n",
    "        \"O processador do computador é rápido e ágil\",  \n",
    "    \n",
    "Esporte\n",
    "\n",
    "        \"A torcida gritou gol no estádio\",              \n",
    "    \n",
    "Tech\n",
    "\n",
    "        \"A inteligência artificial avança no software\", \n",
    "    ]\n",
    "\n",
    "2. Pré-processamento (TF-IDF)\n",
    "    \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf = vectorizer.fit_transform(documents)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "3. Aplicação do NMF\n",
    "\n",
    "Buscando 2 tópicos\n",
    "    \n",
    "        nmf = NMF(n_components=2, init='nndsvd', random_state=1).fit(tfidf)\n",
    "\n",
    "4. Análise dos Resultados\n",
    "\n",
    "        for topic_idx, topic in enumerate(nmf.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-4:-1]]\n",
    "            print(f\"Tópico {topic_idx}: {' '.join(top_words)}\")\n",
    "\n",
    "Classificando os documentos\n",
    "\n",
    "        W = nmf.transform(tfidf)\n",
    "        print(\"\\nClassificação dos Documentos (Pesos):\")\n",
    "        print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d248dc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 0: no gol estádio\n",
      "Tópico 1: ágil processador rápido\n",
      "\n",
      "Classificação dos Documentos (Pesos):\n",
      "[[0.69449633 0.        ]\n",
      " [0.         1.        ]\n",
      " [0.69449633 0.        ]\n",
      " [0.42660423 0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cefra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1728: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"O atacante chutou a bola no gol\",              \n",
    "    \"O processador do computador é rápido e ágil\",  \n",
    "    \"A torcida gritou gol no estádio\",              \n",
    "    \"A inteligência artificial avança no software\", \n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(documents)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "nmf = NMF(n_components=2, init='nndsvd', random_state=1).fit(tfidf)\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    top_words = [feature_names[i] for i in topic.argsort()[:-4:-1]]\n",
    "    print(f\"Tópico {topic_idx}: {' '.join(top_words)}\")\n",
    "\n",
    "W = nmf.transform(tfidf)\n",
    "print(\"\\nClassificação dos Documentos (Pesos):\")\n",
    "print(W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
